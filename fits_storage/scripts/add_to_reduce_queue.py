#! /usr/bin/env python3

import datetime

from fits_storage.config import get_config
fsc = get_config()

from fits_storage.logger import logger, setdebug, setdemon, setlogfilesuffix

from fits_storage.db import session_scope
from fits_storage.core.orm.diskfile import DiskFile
from fits_storage.queues.queue.reducequeue import ReduceQueue
from fits_storage.queues.orm.reducequeentry import debundle_options

from fits_storage.db.list_headers import list_headers
from fits_storage.db.selection.get_selection import from_url_things

from fits_storage.server.reduce_list import parse_listfile

if __name__ == "__main__":
    # Option Parsing
    from argparse import ArgumentParser
    # ------------------------------------------------------------------------------
    parser = ArgumentParser()

    parser.add_argument("--debug", action="store_true", dest="debug",
                        help="Increase log level to debug")

    parser.add_argument("--demon", action="store_true", dest="demon",
                        help="Run in the background, do not generate stdout")

    parser.add_argument("--filenames", action="extend", type=str,
                        dest="filenames", default=[], nargs='+',
                        help="Add this comma separated list of filenames as a "
                             "single entry to the queue")

    parser.add_argument("--listfile", action="store", type=str, default=None,
                        help="Filename of a file containing one or more lists "
                             "of files to add to the queue, each list as a "
                             "single entry. One list per line in the file.")

    parser.add_argument("--selection", action="store", type=str, default=None,
                        help="URL-style selection criteria. Add files matching"
                             "this selection in the database, as individual"
                             "file entries to the reduce queue.")
    parser.add_argument("--initiatedby", action="store", type=str, default=None,
                        help="Processing Initiated By record for reduced data."
                             "Cannot be defaulted in production environments")

    parser.add_argument("--intent", action="store", type=str, default=None,
                        help="Processing Intent record for reduced data. "
                             "Science-Quality or Quick-Look. Can use sq or ql."
                             "Cannot be defaulted in production environments")

    parser.add_argument("--tag", action="store", type=str, default=None,
                        help="Processing Tag record for reduced data."
                             "Cannot be defaulted in production environments")

    parser.add_argument("--recipe", action="store", type=str, default=None,
                        help="DRAGONS recipe name to use. Omit to use"
                             "DRAGONS default")

    parser.add_argument("--debundle", action="store", type=str, default=None,
                        help="Debundle strategy, omit for None - ie no debundling")

    parser.add_argument("--capture_files", action="store_true",
                        help="Capture reduced files output from this processing"
                             " run? Default is False")

    parser.add_argument("--capture_monitoring", action="store_true",
                        help="Capture monitoring values generated by this "
                             "processing run? Default is False")

    parser.add_argument("--logsuffix", action="store", type=str,
                        dest="logsuffix", default=None,
                        help="Extra suffix to add on logfile")

    options = parser.parse_args()

    # Logging level to debug? Include stdio log?
    setdebug(options.debug)
    setdemon(options.demon)

    # Check Log Suffix
    if options.logsuffix:
        setlogfilesuffix(options.logsuffix)

    # Announce startup
    logger.info("*** add_to_reduce_queue.py - starting up at {}"
                .format(datetime.datetime.now()))
    logger.debug("Config files used: %s", ', '.join(fsc.configfiles_used))

    if options.debundle and options.debundle not in debundle_options:
        logger.error("Invalid debundle option: %s", options.debundle)
        exit(1)

    initiatedby = options.initiatedby
    intent = options.intent
    tag = options.tag
    # Check for default processing records in production servers
    if fsc.fits_system_status == 'development':
        if initiatedby is None:
            logger.warning("No Processing Initiated By specified. "
                           "Setting to DEVELOPER")
            initiatedby = 'DEVELOPER'
        if intent is None:
            logger.warning("No Processing Intent specified. "
                           "Setting to Quick-Look")
            intent = 'Quick-Look'
        if tag is None:
            logger.warning("No Processing Tag specified."
                           "Setting to TEST")
            tag = 'TEST'
    else:
        # Not a development server
        if None in (initiatedby, intent, tag):
            logger.error("Required Processing Record not specified, aborting")
            exit(1)

    if options.filenames:
        # Just add a list of filename
        logger.info("Adding single entry list of filenames: %s",
                    options.filenames)
        files = options.filenames
        lists = [files]

    elif options.listfile:
        # Get list(s) of files from list file
        logger.info("Adding files from list file: %s" % options.listfile)
        with open(options.listfile) as fp:
            lists = parse_listfile(fp)

    elif options.selection:
        # Get list from database
        things = options.selection.split('/')
        selection = from_url_things(things)
        logger.info("Selection: %s" % selection)
        if selection.openquery:
            logger.warning("Selection is open - this may not be what you want")

    else:
        logger.info("No list(s) of filenames was provided.")
        lists = []

    with session_scope() as session:

        if options.selection:
            logger.info("Getting header object list")
            headers = list_headers(selection, [], session=session,
                                   unlimit=True)

            # Looping through the header list directly for the add
            # is really slow if the list is big.
            logger.info("Building filename lists")
            lists = []
            for header in headers:
                lists.append([header.diskfile.filename])
            headers = None
            logger.info(f"Selection found {len(lists)} files to add")

        for filelist in lists:
            # Check that all the filenames given are valid and ensure they end
            # in .fits
            validfiles = []
            for filename in filelist:
                if filename.endswith('.fits.bz2'):
                    filename = filename.removesuffix('.bz2')
                elif filename.endswith('.fits'):
                    pass
                else:
                    filename += '.fits'

                possible_filenames = [filename, filename+'.bz2']

                query = session.query(DiskFile) \
                    .filter(DiskFile.present == True)\
                    .filter(DiskFile.filename.in_(possible_filenames))

                if query.count() == 0:
                    logger.error("Filename %s not found in database, not adding "
                                 "this list to the queue", filename)
                else:
                    validfiles.append(filename)

            logger.debug("List of validated files: %s", validfiles)

            if len(validfiles):
                rq = ReduceQueue(session, logger=logger)
                logger.info(f"Queuing a batch of {len(validfiles)} files for "
                            f"reduce, starting with {validfiles[0]}")
                rq.add(validfiles, intent=intent, initiatedby=initiatedby,
                       tag=tag, recipe=options.recipe,
                       capture_files=options.capture_files,
                       capture_monitoring=options.capture_monitoring,
                       debundle=options.debundle)
            else:
                logger.error("No valid files to add")

    logger.info("*** add_to_reducequeue.py exiting normally at %s",
                datetime.datetime.now())
